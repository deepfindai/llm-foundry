max_seq_len: 1024
seed: 1
precision: fp32


models:
-
  model_name: openai/text-babbage-001
  model:
    name: openai
    version: text-babbage-001
  tokenizer:
    name: openai
    kwargs:
      name: text-babbage-001

device_eval_batch_size: 4

# FSDP config for model sharding

icl_tasks: 'eval/yamls/tasks.yaml'
model_gauntlet: 'eval/yamls/model_gauntlet.yaml'
